;------------------------------------------------------------
;------------ WABBIT PARAMETER FILE TEMPLATE ----------------
;------------------------------------------------------------
; if you add new parameters, add them here.
; note values have to be declared "value=0;", with equal sign (=) and semicolon (;)


[Domain]
; 2D or 3D problem?
dim=2;
; box size of computational domain. [Lx Ly Lz]
domain_size=1 1;
; synchronization (on/off)on [x y z] domain boundaries
; (off (NON-PERIODIC): 0/false/yes | on (PERIODIC): 1/true/no)
periodic_BC=0 1;
; symmetry BC. If a problem has e.g, x symmetry (mirror axis is then the y-axis), you'd set 1 0 here.
; symmetry still goes with periodicity in the code: we solve a symmetric periodic problem (cosine-transform)
; this implies all BC in symmetric directions are treated symmetrically (so, at x=const=0 and x=const=Lx)
; While it is possible to also set dirichlet BC on either, we have not currently implemented it.
; Hint: ensure to not impose a meanflow in symmetric directions!
symmetry_BC=1 0;


[Blocks]
; size of each block, must be odd (17, 19, 33, etc), if given one value this is used
; for all directions, or specify value for each direction
number_block_nodes=17 17;
; ghost nodes for each block. you need to know this value depending on the discretization and the multiresolution
; interpolation.
number_ghost_nodes=4;
; number of equations / components of state vector. Note you have to properly
; adjust this value for the physics module that you use.
; ACM: 3 (2D), 4 (3D)
; Convection: 1 (2D /3D)
number_equations=1;
; treelevel bounds: determine the highest (max_treelevel) and lowest (min_treelevel) refinement
; level of blocks. With each refinement level the grid gets refined by a factor of two. The maximum
; resolution at max_treelevel is dx = 2^-max_treelevel * L / Bs (L:domain size, Bs: blocksize)
max_treelevel=6;6
; sometimes you want to restrict the minimum refinement as well, for example if we run equidistant
; simulations (which is quite rare!): in that case, max_treelevel = min_treelevel
min_treelevel=2;1
; max number of trees in the forest. A tree corresponds to a grid; this notation
; only is important for postprocessing, i.e. using the adaptive-POD module. For running
; simulations, you can leave the value empty - it is set automatically.
max_forest_size=22;
; Use adaptivity or not? If adapt_mesh=1 then the grid is refined before a time step,
; the time evolution is done, and the grid is coarsened after the time step. If adapt_mesh=0
; the grid does not change after the initial condition, and refinement/coarsening are disabled.
adapt_mesh=1;
; adaptive initial conditon? i.e. create grid to respect error bounds
; default is same value as adapt_mesh
adapt_inicond=1;
; in some situations, it is necessary to create the intial grid, and then refine it for a couple of times.
; for example if one does non-adaptive non-equidistant spatial convergence tests. default is 0.
inicond_refinements=0;
; block distribution for balancing (also used for start distribution)
; [sfc_z | sfc_hilbert]
; sfc_z  -> space filling curve -> z-curve
; sfc_hilbert -> hilbert space filling curve
block_dist=sfc_hilbert;
; coarsening indicator to be used in mesh adaptation (=coarsening) [threshold-state-vector, random, primary-variables]
; threshold-state-vector: evaluates wavelet criterion on components of state vector. specify below which ones.
; primary-variables: only available for NStokes: converts statevector to (rho,u,v,w,p) before thresholding
; random: randomly coarse some blocks. used for testing. note we tag for coarsening only once in the first iteration
coarsening_indicator=threshold-state-vector;
; use normalization for eps or not? Thresholding means we control the absolute error in some norm (often Linfty norm, see below)
; but very often, you rather want to control the relative error. So, some norm of the field is computed, such that
; || u-u_eps || / ||u|| < eps  (using the norm specified below)
; default=0, even though this is stupid: if you have large pressure (say u=1 and pressure=10000), then only the pressure will determine
; the grid
eps_normalized=1;
; WABBIT uses interpolating, biorthogonal wavelets. These wavelets are, by default, normalized in the Linfty
; norm. That means setting a threshold eps=1.0e-3, we guarantee that the error is < 1.0e-3 in Linfty norm.
; For denoising, we rather need to control the L2 error, because Donohos work is applicable only to the L2 norm.
; For CVS finally, which mimicks applying the denoising to vorticity, we need to control the H1 norm.
; [Linfty (default), L2, H1]
eps_norm=Linfty;
; threshold value for thresholding wavelet coefficients. smaller values imply denser grids. Typical values are ~1e-3
eps=1e-4;
; which components to use for coarsening_indicator? default is all components.
; active only if coarsening_indicator=threshold-state-vector. select the components, set as
; many as number_equations
threshold_state_vector_component=1;
; it can be useful to also use the mask function (if penalization is used) for grid adaptation.
; i.e. the grid is always at the finest level on mask interfaces. Careful though: the Penalization
; is implemented on physics-module level, i.e. it is not available for all modules.
threshold_mask=0;
; if this flag is set (1), then blocks on max level have to coarsen, even if their
; details are significant. This is equivalent to ensuring dealiasing. Hence, if set to 1,
; wabbit will evaluate the right hand side of your equation on max_treelevel, but in the mesh
; coarsening it will, regardless of the solution, downsample the result to max_treelevel-1. Your
; expected precision is thus max_treelevel-1, but the computational cost (derivatives and timestep)
; is on max_treelevel.
force_maxlevel_dealiasing=0;
; if desired, we perform more than one time step
; before adapting the grid again. this can further reduce the overhead of adaptivity
; Note: the non-linear terms can create finer scales than resolved on the grid. they
; are usually filtered by the coarsening/refinement round trip. So if you do more than one time step
; on the grid, consider using a filter. default is "1", which is the classical scheme
N_dt_per_grid=1;


[Time]
; final time to reach in simulation
time_max=0.25;
; maximum walltime allowed for simulations (in hours). The run will be stopped if this duration
; is exceeded. This is useful on real clusters, where the walltime of a job is limited, and the
; system kills the job regardless of whether we're done or not. If WABBIT itself ends execution,
; a backup is written and you can resume the simulation right where it stopped. Note you can also
; stop a run using the file "runtime_control" (set runtime_control=save_stop;)
walltime_max=999.9;
; While we can save every write_time time units of the simulation, it may be desirable to save also
; every couple of hours of runtime (for very expensive runs) so that we can be sure to be able to
; resume the simulation with at most the loss of these hours. default unused, set value in HOURS.
walltime_write=;
; number of time steps performed. if not set, default value is very large
nt=;
; CFL criterium (velocity). Note the time step dt is dictated by the physics modules: some eqns (like
; the heat eqn, which is not implemented) may not even have a CFL restriction.
CFL=1.2;
; CFL critierum for penalization (dt<=CFL_eta*C_eta), if VPM is used. For RungeKuttaGeneric schemes, the constant
; has to be < 1.0 (otherwise the code is unstable). For krylov schemes, it can be greater
; 1, but be careful about the error. This parameter is used by ACM physics module only.
CFL_eta=0.99;
; time step restriction of viscous terms ( dt < CFL_NU * dx**2 / nu )
; runge kutta 4 has constraints: 2D=>0.14 3D=>0.094 (exact expression: 2.79/(dim*pi**2)), these are
; the default values
CFL_nu=;
; wabbit can save the heavy data (flow fiels) to HDF5. What is saved depends on the physics modules
; and the section [Saving]. Here you control WHEN you want to save the output: either after a fixed
; number of time steps [fixed_freq], or after a physical time interval [fixed_time]
write_method=fixed_time;
; if write_method=fixed_freq:
; write frequency for output, choose very large number for disabling output on disk
write_freq=1;
; if write_method=fixed_time:
; write time for output
write_time=0.25;
; time-step method. can be either "RungeKuttaGeneric" or "Krylov". In the former case,
; any explicit Runge-Kutta scheme can be set by using the Butcher-Tableau. (RK4 is default) In the latter,
; the number of Krylov subspaces M_krylov can be set.
; [ RungeKuttaGeneric, Krylov, RungeKuttaChebychev ]
time_step_method=RungeKuttaGeneric;


[Physics]
; what physics module is used?
; [ACM-new, ConvDiff-new, navier_stokes]
physics_type=ConvDiff-new;
; decide if you want to start from a given configuration (i.e. Statevector)
; 1:true, 0:false and we start from the initial conditions dictated by the physics
; modue.
read_from_files=0;
; sometimes you want to save the iteration number as fileid instead of the time:
use_iteration_as_fileid=0;
; if read_from_files is true, WABBIT will try to start from the given files
input_files=phi_000000000000.h5.h6;


[Saving]
; WABBIT is in charge of saving, but what is saved is controled by the physics modules.
; here, you need to tell WABBIT how many fields are saved and how they will be labeled.
; The physics modules are then in charge of providing the respective data to WABBIT. I.e.
; if the field is called "mask", WABBIT will ask the physics module to return the array
; "mask" and then save that to disk.
; how many fields are you going to save?
N_fields_saved=1;
; how are the fields labeled?
field_names=phi;


[Statistics]
; save every nsave time steps (leave empty to disable)
nsave_stats=10;
; and every tsave physical time units (leave empty to disable)
tsave_stats=0.20;

[ConvectionDiffusion]
; how many scalar fields do you want to solve? should be the same as number_equations
; above.
N_scalars=1;
; note you need to specify one value per scalar field for ALL the below parameters
; viscosity. if nu<1.0e-10 (or 0.0), diffusion is disabled.
nu=0.0e-6;
; initial condition for the scalar(s)
inicond=blob;
blob_width=0.001;
; position of blob
x0=0.0;
y0=0.5;
z0=0;
; velocity field for transportation, [swirl,constant]
velocity=constant;
; if the velocity profile is the swirl test, one sometimes would want to compute
; an incomplete swirl, i.e. Tmax and Tswirl to not agree. Set T_swirl here if you want
; the default is the same as the simulation duration
T_swirl=5.0;
; if constant velocity, these are the values (one per scalar)
u0x=0.0;
u0y=1.0;
u0z=0.0;


[Wavelet]
; if we use harten-multiresolution, the coarsening operator is just taking every second
; grid point. This is nice and local but the resulting wavelet has no vannishing moments.
; If biorthogonal is used, a smoothing low-pass filter is applied prior to downsampling.
; The biorthogonal option does however use harten for the ghost nodes at this time (09/2019)
transform_type=harten-multiresolution; biorthogonal;
; only used if transform_type=biorthogonal
wavelet=CDF4,4;


[Discretization]
; order of derivatives [ FD_2nd_central | FD_4th_central_optimized ]
order_discretization=FD_4th_central_optimized;
; order of refinement predictor [ multiresolution_4th | multiresolution_2nd ]
order_predictor=multiresolution_4th;


[Debug]
; check if the ghost node synchronization gives the right order, on a random
; grid. this test costs some CPU time but no memory. It is done only once at startup.
test_ghost_nodes_synch=1;
